// src/views/GenerativeIDE.tsx - MINIMALIST REDESIGN
import React, { useState, useEffect, useRef } from 'react';
import { Send, Zap, Cpu, Settings, ChevronDown } from 'lucide-react';
import { HardenedRezStackRouter } from '../services/hardened-router';
import { REZSTACK_MODEL_ROSTER } from '../config/model-strengths';
import { OllamaStreamService } from '../services/ollama-stream-service';
import { ModelSelector } from '../components/ModelSelector';
import { WelcomeScreen } from '../components/WelcomeScreen';
import { vramSafety } from '../services/vram-safety';
import { gpuAnalyzer, SystemProfile } from '../services/gpu-analyzer';

interface GenerativeIDEProps {
  availableModels: string[];
}

interface Message {
  id: string;
  role: 'user' | 'assistant';
  content: string;
  model?: string;
  timestamp: Date;
}

export const GenerativeIDE: React.FC<GenerativeIDEProps> = ({ availableModels = [] }) => {
  const [prompt, setPrompt] = useState('');
  const [messages, setMessages] = useState<Message[]>([]);
  const [streamingText, setStreamingText] = useState('');
  const [isProcessing, setIsProcessing] = useState(false);
  const [systemProfile, setSystemProfile] = useState<SystemProfile | null>(null);
  const [showWelcome, setShowWelcome] = useState(false);
  const [currentModel, setCurrentModel] = useState('');
  const [showModelSelector, setShowModelSelector] = useState(false);

  const router = useRef(new HardenedRezStackRouter());
  const ollamaService = useRef(new OllamaStreamService());
  const messagesEndRef = useRef<HTMLDivElement>(null);

  useEffect(() => {
    const initSystem = async () => {
      const profile = gpuAnalyzer.getProfile();
      if (!profile?.analyzed) {
        setShowWelcome(true);
      } else {
        setSystemProfile(profile);
        vramSafety.setSystemProfile(profile);
        setCurrentModel(profile.ollama.modelsInstalled[0] || 'llama3.2:latest');
      }
    };
    initSystem();
  }, []);

  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages, streamingText]);

  const handleModelChange = (modelId: string, forced: boolean) => {
    if (currentModel) vramSafety.unregisterModelLoad(currentModel);
    vramSafety.registerModelLoad(modelId);
    setCurrentModel(modelId);
    setShowModelSelector(false);
  };

  const handleSend = async () => {
    if (!prompt.trim() || isProcessing || !currentModel) return;

    const userMessage: Message = {
      id: Date.now().toString(),
      role: 'user',
      content: prompt,
      timestamp: new Date()
    };
    setMessages(prev => [...prev, userMessage]);
    setPrompt('');
    setIsProcessing(true);

    let fullResponse = '';
    
    await ollamaService.current.generate(currentModel, prompt, {
      onChunk: (chunk) => {
        fullResponse += chunk;
        setStreamingText(fullResponse);
      },
      onComplete: () => {
        const aiMessage: Message = {
          id: (Date.now() + 1).toString(),
          role: 'assistant',
          content: fullResponse,
          model: currentModel,
          timestamp: new Date()
        };
        setMessages(prev => [...prev, aiMessage]);
        setStreamingText('');
        setIsProcessing(false);
        vramSafety.unregisterModelLoad(currentModel);
      },
      onError: (error) => {
        console.error('Generation failed:', error);
        setStreamingText('');
        setIsProcessing(false);
        vramSafety.unregisterModelLoad(currentModel);
      }
    });
  };

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSend();
    }
  };

  if (showWelcome) {
    return (
      <WelcomeScreen
        onComplete={(profile) => {
          setSystemProfile(profile);
          vramSafety.setSystemProfile(profile);
          setShowWelcome(false);
          setCurrentModel(profile.ollama.modelsInstalled[0] || 'llama3.2:latest');
        }}
      />
    );
  }

  const vramStatus = vramSafety.getStatus();
  const modelInfo = currentModel ? REZSTACK_MODEL_ROSTER[currentModel] : null;

  return (
    <div className="h-screen bg-gradient-to-br from-gray-950 via-gray-900 to-gray-950 flex flex-col">
      {/* MINIMALIST HEADER - Single line, all critical info */}
      <header className="border-b border-white/5 backdrop-blur-xl bg-white/[0.02]">
        <div className="max-w-7xl mx-auto px-6 h-16 flex items-center justify-between">
          {/* Left: Branding */}
          <div className="flex items-center gap-3">
            <div className="w-8 h-8 rounded-lg bg-gradient-to-br from-purple-500 to-blue-500 flex items-center justify-center">
              <Zap className="w-5 h-5 text-white" />
            </div>
            <div>
              <h1 className="text-sm font-semibold text-white">RezStack</h1>
              <p className="text-xs text-gray-500">GPU-Aware AI</p>
            </div>
          </div>

          {/* Center: Model Selector - Clean dropdown */}
          <button
            onClick={() => setShowModelSelector(!showModelSelector)}
            className="group relative flex items-center gap-3 px-4 py-2 rounded-xl bg-white/5 hover:bg-white/10 border border-white/10 transition-all"
          >
            <Cpu className="w-4 h-4 text-purple-400" />
            <div className="text-left">
              <div className="text-xs text-gray-400">Model</div>
              <div className="text-sm font-medium text-white">
                {modelInfo?.name || currentModel}
              </div>
            </div>
            <ChevronDown className="w-4 h-4 text-gray-500 group-hover:text-white transition" />
            
            {/* Dropdown */}
            {showModelSelector && systemProfile && (
              <div className="absolute top-full mt-2 right-0 w-96 bg-gray-900 border border-white/10 rounded-xl shadow-2xl overflow-hidden z-50">
                <ModelSelector
                  currentModel={currentModel}
                  onModelChange={handleModelChange}
                  systemProfile={systemProfile}
                  disabled={isProcessing}
                />
              </div>
            )}
          </button>

          {/* Right: GPU Stats - Compact */}
          <div className="flex items-center gap-4">
            <div className="text-right">
              <div className="text-xs text-gray-500">VRAM</div>
              <div className="text-sm font-mono text-purple-400">
                {vramStatus.usedVRAM.toFixed(1)}/{vramStatus.totalVRAM}GB
              </div>
            </div>
            <div className="w-24 h-2 bg-white/5 rounded-full overflow-hidden">
              <div 
                className="h-full bg-gradient-to-r from-purple-500 to-blue-500 transition-all"
                style={{ width: `${vramStatus.utilizationPercent}%` }}
              />
            </div>
          </div>
        </div>
      </header>

      {/* MAIN: Chat Messages - Clean, spacious */}
      <main className="flex-1 overflow-y-auto px-6 py-8">
        <div className="max-w-4xl mx-auto space-y-6">
          {messages.map((msg) => (
            <div
              key={msg.id}
              className={`flex gap-4 ${msg.role === 'user' ? 'justify-end' : 'justify-start'}`}
            >
              <div
                className={`max-w-2xl rounded-2xl px-6 py-4 ${
                  msg.role === 'user'
                    ? 'bg-gradient-to-br from-purple-500/20 to-blue-500/20 border border-purple-500/20'
                    : 'bg-white/5 border border-white/10'
                }`}
              >
                <div className="text-sm text-white whitespace-pre-wrap font-mono leading-relaxed">
                  {msg.content}
                </div>
                {msg.role === 'assistant' && msg.model && (
                  <div className="mt-3 pt-3 border-t border-white/10 flex items-center gap-2 text-xs text-gray-500">
                    <Cpu className="w-3 h-3" />
                    {REZSTACK_MODEL_ROSTER[msg.model]?.name || msg.model}
                  </div>
                )}
              </div>
            </div>
          ))}

          {/* Streaming message */}
          {streamingText && (
            <div className="flex gap-4 justify-start">
              <div className="max-w-2xl rounded-2xl px-6 py-4 bg-white/5 border border-white/10">
                <div className="text-sm text-white whitespace-pre-wrap font-mono leading-relaxed">
                  {streamingText}
                  <span className="inline-block w-2 h-4 bg-purple-500 ml-1 animate-pulse" />
                </div>
              </div>
            </div>
          )}

          {/* Empty state */}
          {messages.length === 0 && !streamingText && (
            <div className="text-center py-20">
              <div className="w-16 h-16 rounded-2xl bg-gradient-to-br from-purple-500/20 to-blue-500/20 border border-purple-500/20 flex items-center justify-center mx-auto mb-6">
                <Zap className="w-8 h-8 text-purple-400" />
              </div>
              <h2 className="text-xl font-semibold text-white mb-2">Ready to code</h2>
              <p className="text-gray-500 mb-8">
                {systemProfile?.gpu.name} • {systemProfile?.ollama.modelsInstalled.length} models
              </p>
              <div className="flex flex-wrap gap-3 justify-center max-w-2xl mx-auto">
                {[
                  'Write a React component',
                  'Explain async/await',
                  'Debug this error',
                  'Optimize this function'
                ].map((example, i) => (
                  <button
                    key={i}
                    onClick={() => setPrompt(example)}
                    className="px-4 py-2 rounded-lg bg-white/5 hover:bg-white/10 border border-white/10 text-sm text-gray-400 hover:text-white transition"
                  >
                    {example}
                  </button>
                ))}
              </div>
            </div>
          )}

          <div ref={messagesEndRef} />
        </div>
      </main>

      {/* FOOTER: Input - Clean, powerful */}
      <footer className="border-t border-white/5 backdrop-blur-xl bg-white/[0.02]">
        <div className="max-w-4xl mx-auto px-6 py-6">
          <div className="relative">
            <textarea
              value={prompt}
              onChange={(e) => setPrompt(e.target.value)}
              onKeyDown={handleKeyPress}
              placeholder="Ask anything..."
              disabled={isProcessing}
              className="w-full bg-white/5 border border-white/10 rounded-2xl px-6 py-4 pr-24 text-white placeholder-gray-500 resize-none focus:outline-none focus:border-purple-500/50 focus:bg-white/10 transition disabled:opacity-50 font-mono text-sm"
              rows={3}
            />
            <button
              onClick={handleSend}
              disabled={isProcessing || !prompt.trim() || !currentModel}
              className="absolute bottom-4 right-4 w-12 h-12 rounded-xl bg-gradient-to-br from-purple-500 to-blue-500 hover:from-purple-600 hover:to-blue-600 disabled:opacity-50 disabled:cursor-not-allowed flex items-center justify-center transition-all transform hover:scale-105 active:scale-95"
            >
              <Send className="w-5 h-5 text-white" />
            </button>
          </div>
          <div className="mt-3 flex items-center justify-between text-xs text-gray-500">
            <div>Press Enter to send • Shift+Enter for new line</div>
            <div className="flex items-center gap-2">
              {isProcessing && (
                <>
                  <div className="w-2 h-2 rounded-full bg-purple-500 animate-pulse" />
                  <span>Generating...</span>
                </>
              )}
            </div>
          </div>
        </div>
      </footer>
    </div>
  );
};